{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pattern_Project",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-SYAuCvpqMi",
        "colab_type": "code",
        "outputId": "7fd0f2b6-2247-4789-c6c1-4a2a769951aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 65
        }
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcEoHqY4w1j0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import string"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNsz394irQMd",
        "colab_type": "code",
        "outputId": "4c5fc811-e600-4cf9-b2c9-4677d45888bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6PbMJHPFtAfJ",
        "colab_type": "code",
        "outputId": "3f7d467b-fe13-4e58-8a78-06b0224d022d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "%cd /content/gdrive/My \\Drive/PatternProject\n",
        "!ls"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/PatternProject\n",
            "data.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ECEwLt1MtKOO",
        "colab_type": "text"
      },
      "source": [
        "Here we read the data and save it to the X and Y variables!\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B5zv4RfTtAAk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data = pd.read_csv('data.csv', keep_default_na=False)\n",
        "X = data['Raw']\n",
        "Y = data['Encrypt']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0uEwS6Uw4qa",
        "colab_type": "text"
      },
      "source": [
        "# **Character Based Methods - Simple Neural Network**\n",
        "In this part we focused on the charachters being change in the encryption. There are lots of models that can be used for this problem like: single perceptron, fully connected neural networks and so on!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pA3il_qRx2x_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# we get all the upper case letters\n",
        "characters = list(string.ascii_uppercase) + list(string.punctuation) + list(string.digits) +list(string.ascii_lowercase) + list(' ')\n",
        "N = len(characters)\n",
        "# print(characters)\n",
        "# print(characters.index(str(1)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNIF78WL0tV_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot_vector(char):\n",
        "  idx = characters.index(str(char)) \n",
        "  vector = np.zeros(N)\n",
        "  vector[idx] = 1\n",
        "  return vector"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uveCI4XldoDE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_hot_to_char(vect):\n",
        "  result = np.where(vect == np.amax(vect))\n",
        "  idx = result[1][0]\n",
        "  return characters[idx]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpB8hEi5EGz3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def change_data(x, y):\n",
        "  new_x, new_y = [], []\n",
        "  for k in x:\n",
        "    for e in k:\n",
        "      vect = one_hot_vector(e)\n",
        "      new_x.append(vect)\n",
        "  new_x = np.array(new_x)\n",
        "\n",
        "  for k in y:\n",
        "      for e in str(k):\n",
        "        vect = one_hot_vector(e)\n",
        "        new_y.append(vect)\n",
        "  new_y = np.array(new_y)\n",
        "\n",
        "  return new_x, new_y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10IX3uP0nPSU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 10\n",
        "batch_size = 256"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xdQpw1Kn1IV-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def model():\n",
        "  model = keras.Sequential([\n",
        "        keras.layers.Input(shape=(N,)),\n",
        "        keras.layers.Dense(32, activation='relu'),\n",
        "        keras.layers.Dense(N, activation='sigmoid')\n",
        "  ])\n",
        "  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "  print(model.summary())\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "788vLz6OA2bD",
        "colab_type": "code",
        "outputId": "fe6a133e-cd61-4c8a-af74-638091e5decc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        }
      },
      "source": [
        "# creating the model\n",
        "mymodel = model()\n",
        "# preprocessing data accourding to model architecture\n",
        "new_x, new_y = change_data(X, Y)\n",
        "m = len(new_x)\n",
        "split = int(0.8*m)\n",
        "x_train, y_train, x_test, y_test = new_x[:split], new_y[:split], new_x[split:], new_y[split:]\n",
        "\n",
        "mymodel.fit(x_train, y_train, epochs=epochs, batch_size=batch_size)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 32)                3072      \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 95)                3135      \n",
            "=================================================================\n",
            "Total params: 6,207\n",
            "Trainable params: 6,207\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n",
            "Train on 987147 samples\n",
            "Epoch 1/10\n",
            "987147/987147 [==============================] - 14s 15us/sample - loss: 0.2781 - acc: 0.9828\n",
            "Epoch 2/10\n",
            "987147/987147 [==============================] - 14s 14us/sample - loss: 3.6279e-04 - acc: 1.0000\n",
            "Epoch 3/10\n",
            "987147/987147 [==============================] - 14s 14us/sample - loss: 7.3269e-05 - acc: 1.0000\n",
            "Epoch 4/10\n",
            "987147/987147 [==============================] - 14s 14us/sample - loss: 2.8815e-05 - acc: 1.0000\n",
            "Epoch 5/10\n",
            "987147/987147 [==============================] - 14s 14us/sample - loss: 1.5352e-05 - acc: 1.0000\n",
            "Epoch 6/10\n",
            "987147/987147 [==============================] - 14s 15us/sample - loss: 1.0779e-05 - acc: 1.0000\n",
            "Epoch 7/10\n",
            "987147/987147 [==============================] - 14s 14us/sample - loss: 7.4762e-06 - acc: 1.0000\n",
            "Epoch 8/10\n",
            "987147/987147 [==============================] - 15s 15us/sample - loss: 6.5602e-06 - acc: 1.0000\n",
            "Epoch 9/10\n",
            "987147/987147 [==============================] - 14s 14us/sample - loss: 5.4981e-06 - acc: 1.0000\n",
            "Epoch 10/10\n",
            "987147/987147 [==============================] - 14s 14us/sample - loss: 4.0573e-06 - acc: 1.0000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6c1d7947f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "np9y5W-15SNG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "pickle.dumps(mymodel)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEWpcjF0UEYq",
        "colab_type": "text"
      },
      "source": [
        "Predicting a single charachter"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WR4CCUInb69Z",
        "colab_type": "code",
        "outputId": "b05d2327-53d8-4a96-eda3-ad31497c346d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "# test the model here\n",
        "test1 = one_hot_vector('X')\n",
        "test1 = test1.reshape(1,N)\n",
        "vect = mymodel.predict(test1)\n",
        "print(one_hot_to_char(vect))\n",
        "\n",
        "mystring = 'AABD./ N'\n",
        "mystring = 'AAB./'\n",
        "ans = ''\n",
        "for c in mystring:\n",
        "  test1 = one_hot_vector(c)\n",
        "  test1 = test1.reshape(1,N)\n",
        "  vect = mymodel.predict(test1)\n",
        "  ans += one_hot_to_char(vect)\n",
        "print(ans)"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "J\n",
            "MMN./\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6B3EkQSUOlH",
        "colab_type": "text"
      },
      "source": [
        "Predicting test data and caculating the accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nk4Ju2d2UOMd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pred_y = mymodel.predict(x_test)\n",
        "for i in range(len(pred_y)):\n",
        "  idx = np.argmax(pred_y[i])\n",
        "  pred_y[i, idx] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Z0JcQXAXeKz",
        "colab_type": "code",
        "outputId": "220b3091-f77a-4f94-918b-d942c5960001",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.metrics import average_precision_score, accuracy_score, confusion_matrix\n",
        "\n",
        "m = len(y_test)\n",
        "pred_labels = [np.argmax(pred_y[i]) for i in range(m)]\n",
        "test_labels = [np.argmax(y_test[i]) for i in range(m)]\n",
        "\n",
        "# average_precision = average_precision_score(test_labels, pred_labels)\n",
        "accuracy = accuracy_score(test_labels, pred_labels)\n",
        "# cm = confusion_matrix(test_labels, pred_labels)\n",
        "\n",
        "# print('The Average Score Of Precision and Recall is: ', str(average_precision))\n",
        "print('The Score Of Accuracy is: ', str(accuracy))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Score Of Accuracy is:  1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arSVkVW6ahPq",
        "colab_type": "text"
      },
      "source": [
        "# **Using Deep Learning Models - CNN and Seq-to-Seq**\n",
        "In this section we try to use different deep learning models such as CNN and sequence-to-sequence models. The intuition for using a seq2seq model is that we are trying to decode an encoded sequence of charachters. So it is important to capture the relations (if there are any!) between characters in a single encoded text. \n",
        "\n",
        "CNN are mostly used in image processing but they have been applied for text as well in character level. As we are focusing on characters in this project we can also use CNNs to see how it works. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1C0vClWoz-MJ",
        "colab_type": "text"
      },
      "source": [
        "reading the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NCNqHbkH8FNw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len_tokens = 35"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CboKWh1FaoTy",
        "colab_type": "code",
        "outputId": "09d0c563-d347-4fb1-82ae-69fa791e41e6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# here we use keras library to get the one-hot vector of out input data. first we need to make our train and test data integers\n",
        "# then we can use scikit learn to_categorical() to get the one-hot vector.\n",
        "tokenizer = Tokenizer(char_level=True)\n",
        "tokenizer.fit_on_texts(pd.concat([X, Y]))\n",
        "number_of_chars = len(tokenizer.word_index)\n",
        "\n",
        "m = len(X)\n",
        "split = int(0.8*m)\n",
        "\n",
        "# getting the sequence of numbers that represent the character\n",
        "x_train = np.asarray(tokenizer.texts_to_sequences(X.iloc[:split]))\n",
        "y_train = np.asarray(tokenizer.texts_to_sequences(Y.iloc[:split]))\n",
        "x_test = np.asarray(tokenizer.texts_to_sequences(X.iloc[split:]))\n",
        "y_test = np.asarray(tokenizer.texts_to_sequences(Y.iloc[split:]))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TcAwj5-w7UGc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def string_to_int_sequence(s):\n",
        "  arr = np.asarray(tokenizer.texts_to_sequences(s))\n",
        "  return arr"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ilO4JtlmwNv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# make the one-hot with padding\n",
        "def make_arr(mat):\n",
        "  u = len(mat)\n",
        "  tmp = np.zeros((u, max_len_tokens, number_of_chars))\n",
        "  for i in range(u):\n",
        "    for j in range(len(mat[i])):\n",
        "      tmp[i][j][mat[i][j]-1] = 1\n",
        "  return tmp"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDcxmqxCeUoE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# this is the list of all sequence of characters that are converted to one-hot and have padding\n",
        "new_x_train = make_arr(x_train)\n",
        "new_y_train = make_arr(y_train)\n",
        "new_x_test = make_arr(x_test)\n",
        "new_y_test = make_arr(y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kVcfiSoIlFAP",
        "colab_type": "code",
        "outputId": "cf6c6eb8-c03b-4542-c5cc-9304eeb489cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "print(new_x_train.shape)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(107613, 35, 35)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oc4gVP3Nz59d",
        "colab_type": "text"
      },
      "source": [
        "**Sequence-to-Sequence Model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "94Bf-tBvizaW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def seq2seq(max_len_tokens):\n",
        "  encoder_inputs = keras.layers.Input(shape=(max_len_tokens, number_of_chars), name='encoder_input')\n",
        "  encoder = keras.layers.LSTM(300, return_state=True, name='encoder_lstm', activation='linear')\n",
        "  encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
        "  \n",
        "  encoder_states = [state_h, state_c]\n",
        "\n",
        "  decoder_inputs = keras.layers.Input(shape=(max_len_tokens-1, number_of_chars), name='decoder_input')\n",
        "  decoder_lstm = keras.layers.LSTM(300, return_sequences=True, return_state=True, name='decoder_lstm', activation='linear')\n",
        "  decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
        "  decoder_dense = keras.layers.Dense(number_of_chars, activation='sigmoid', name='dense_layer')\n",
        "  decoder_outputs = decoder_dense(decoder_outputs)\n",
        "\n",
        "  model = keras.Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
        "\n",
        "  model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "  print(model.summary())\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37bLA2eAs-ns",
        "colab_type": "code",
        "outputId": "59fcba57-504d-4c66-bc55-8855fa4d0d49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        }
      },
      "source": [
        "model = seq2seq(max_len_tokens)\n",
        "decoder_input = new_y_train[:,0:max_len_tokens-1,:]\n",
        "decoder_target = new_y_train[:,1:max_len_tokens,:]\n",
        "\n",
        "callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "\n",
        "model.fit([new_x_train, decoder_input], decoder_target, batch_size=batch_size, epochs=1, callbacks=[callback], validation_split=0.2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_17\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "encoder_input (InputLayer)      [(None, 35, 35)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "decoder_input (InputLayer)      [(None, 34, 35)]     0                                            \n",
            "__________________________________________________________________________________________________\n",
            "encoder_lstm (LSTM)             [(None, 300), (None, 403200      encoder_input[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "decoder_lstm (LSTM)             [(None, 34, 300), (N 403200      decoder_input[0][0]              \n",
            "                                                                 encoder_lstm[0][1]               \n",
            "                                                                 encoder_lstm[0][2]               \n",
            "__________________________________________________________________________________________________\n",
            "dense_layer (Dense)             (None, 34, 35)       10535       decoder_lstm[0][0]               \n",
            "==================================================================================================\n",
            "Total params: 816,935\n",
            "Trainable params: 816,935\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n",
            "None\n",
            "Train on 107613 samples, validate on 26904 samples\n",
            "107613/107613 [==============================] - 725s 7ms/sample - loss: 1.1319 - acc: 0.7607 - val_loss: 1.2247 - val_acc: 0.7767\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f674871bdd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szRahZpyYeZG",
        "colab_type": "text"
      },
      "source": [
        "**Using CNN**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pakyel84Yd7e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cnn_model():\n",
        "  model = keras.Sequential([\n",
        "            keras.layers.Input(shape=(max_len_tokens, number_of_chars), name='input_layer'),\n",
        "            keras.layers.Conv1D(strides=1, padding='same', activation='relu', kernel_size=3, filters=300, name='convolution_layer1'),\n",
        "            keras.layers.MaxPool1D(),\n",
        "            keras.layers.Conv1D(strides=1, padding='same', activation='relu', kernel_size=4, filters=300, name='convolution_layer2'),\n",
        "            keras.layers.Dropout(0.5),\n",
        "            keras.layers.Flatten(),\n",
        "            keras.layers.Dense(number_of_chars, activation='relu', name='dense_layer')\n",
        "  ])\n",
        "\n",
        "  model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
        "  model.summary()\n",
        "\n",
        "  return model "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W5f7zxPwUtYj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# the target value is the vector of all integers that represent the int value of character\n",
        "def make_y_vector(mat):\n",
        "  l = len(mat)\n",
        "  v = np.zeros((l, max_len_tokens))\n",
        "  v = np.zeros((l, 1))\n",
        "  for i in range(l):\n",
        "    # idx = np.argmax(pred_y[i])\n",
        "    # v[i][0] = idx \n",
        "    for j in range(len(mat[i])):\n",
        "      v[i][j] = mat[i][j]\n",
        "  return v"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DYkkWK7yWOd9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(make_y_vector(y_train).shape)\n",
        "print(y_train.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itOXwTsyZ0j6",
        "colab_type": "code",
        "outputId": "559b2e7b-3cd3-4885-c9b6-4d950966d003",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 788
        }
      },
      "source": [
        "cnnmodel = cnn_model()\n",
        "callback = keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\n",
        "cnnmodel.fit(new_x_train, make_y_vector(y_train), epochs=epochs, batch_size=batch_size, callbacks=[callback], validation_split=0.2)\n",
        "pickel.dumps(cnnmodel)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_layer1 (Conv1D)  (None, 35, 300)           31800     \n",
            "_________________________________________________________________\n",
            "max_pooling1d (MaxPooling1D) (None, 17, 300)           0         \n",
            "_________________________________________________________________\n",
            "convolution_layer2 (Conv1D)  (None, 17, 300)           360300    \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 17, 300)           0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 5100)              0         \n",
            "_________________________________________________________________\n",
            "dense_layer (Dense)          (None, 35)                178535    \n",
            "=================================================================\n",
            "Total params: 570,635\n",
            "Trainable params: 570,635\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 86090 samples, validate on 21523 samples\n",
            "Epoch 1/10\n",
            "86090/86090 [==============================] - 145s 2ms/sample - loss: 5.9919 - acc: 0.5519 - val_loss: 3.4897 - val_acc: 0.6942\n",
            "Epoch 2/10\n",
            "86090/86090 [==============================] - 142s 2ms/sample - loss: 0.6143 - acc: 0.8454 - val_loss: 3.0674 - val_acc: 0.6938\n",
            "Epoch 3/10\n",
            "86090/86090 [==============================] - 146s 2ms/sample - loss: 0.4396 - acc: 0.8631 - val_loss: 2.7263 - val_acc: 0.7018\n",
            "Epoch 4/10\n",
            "86090/86090 [==============================] - 144s 2ms/sample - loss: 0.3854 - acc: 0.8735 - val_loss: 2.6448 - val_acc: 0.7131\n",
            "Epoch 5/10\n",
            "86090/86090 [==============================] - 144s 2ms/sample - loss: 0.3620 - acc: 0.8770 - val_loss: 2.5725 - val_acc: 0.7200\n",
            "Epoch 6/10\n",
            "86090/86090 [==============================] - 144s 2ms/sample - loss: 0.3456 - acc: 0.8779 - val_loss: 2.5405 - val_acc: 0.7256\n",
            "Epoch 7/10\n",
            "86090/86090 [==============================] - 143s 2ms/sample - loss: 0.3353 - acc: 0.8788 - val_loss: 2.3349 - val_acc: 0.7290\n",
            "Epoch 8/10\n",
            "86090/86090 [==============================] - 144s 2ms/sample - loss: 0.3263 - acc: 0.8804 - val_loss: 2.2500 - val_acc: 0.7390\n",
            "Epoch 9/10\n",
            "86090/86090 [==============================] - 143s 2ms/sample - loss: 0.3196 - acc: 0.8801 - val_loss: 2.3366 - val_acc: 0.7354\n",
            "Epoch 10/10\n",
            "86090/86090 [==============================] - 142s 2ms/sample - loss: 0.3159 - acc: 0.8834 - val_loss: 2.2315 - val_acc: 0.7382\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6c23a8ec88>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WmgKcKC5aFpa",
        "colab_type": "code",
        "outputId": "ed9b08f9-1f4d-4596-b77d-305b54b07cf6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "from sklearn.metrics import average_precision_score, accuracy_score, confusion_matrix\n",
        "# now it's time for testing\n",
        "y_pred = cnnmodel.predict(new_x_test)\n",
        "# # make the float value round (as they are all indexes)\n",
        "for i in range(len(y_pred)):\n",
        "  y_pred[i] = np.round(y_pred[i])\n",
        "\n",
        "arr_y_test = make_y_vector(y_test).astype(int)\n",
        "y_pred = y_pred.astype(int)\n",
        "\n",
        "correct = 0\n",
        "total = 0\n",
        "for i in range(y_pred.shape[0]):\n",
        "  for j in range(y_pred.shape[1]):\n",
        "    if y_pred[i][j] == arr_y_test[i][j]:\n",
        "      correct += 1\n",
        "    total += 1\n",
        "\n",
        "print('The Accuracy Of The Model Is: ', str(correct/total))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Accuracy Of The Model Is:  0.8643558047661527\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XsMY6I2jsPby",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "2e6c1b3a-95d3-485e-c7e7-d140bdde257a"
      },
      "source": [
        "reverse_word_map = dict(map(reversed, tokenizer.word_index.items()))\n",
        "mystring = ['AAB./']\n",
        "print(string_to_int_sequence(mystring))\n",
        "s = make_arr(string_to_int_sequence(mystring))\n",
        "pred = cnnmodel.predict(s)\n",
        "ans = ''\n",
        "for i in range(len(pred)):\n",
        "  for x in pred[i]:\n",
        "    if x > 0:\n",
        "      ans += reverse_word_map[int(round(x))]\n",
        "\n",
        "print(ans)"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 1  1 19 29 30]]\n",
            "mmt'w\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLv9iLZSLclu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}